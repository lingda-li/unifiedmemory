\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables


% Copyright
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


%% DOI
%\acmDOI{10.475/123_4}
%
%% ISBN
%\acmISBN{123-4567-24-567/08/06}
%
%%Conference
%\acmConference[WOODSTOCK'97]{ACM Woodstock conference}{July 1997}{El
%  Paso, Texas USA} 
%\acmYear{1997}
%\copyrightyear{2016}
%
%\acmPrice{15.00}


\begin{document}
\title{Exploring Data Locality for GPU Unified Virtual Memory}


%\author{Lingda Li}
%\authornote{Dr.~Trovato insisted his name be first.}
%\affiliation{%
%  \institution{Brookhaven National Laboratory}
%  \city{Upton} 
%  \state{NY} 
%}
%\email{lli@bnl.gov}


\begin{abstract}

To facilitate GPU programming and accelerate applications with large working set, recent GPUs support unified CPU/GPU memory addressing and on-demand page migration. However, our investigation shows that current page migration mechanism is not aware of data locality, resulting in poor performance and redundant data movement. To improve the performance and energy efficiency of GPU unified memory, we propose a framework to achieve intelligent unified memory management using both compile-time and runtime information. Compiler collects information such as data access pattern and reuse frequency and passes them to runtime library, and then runtime makes data placement decisions based on both current hardware status and compiler analysis results. The proposed scheme can benefit both directive based GPU programming models such as OpenMP and native GPU programming languages such as CUDA. Our preliminary evaluation shows that our framework can significantly improve GPU performance and reduce redundant data movement between CPU and GPU for benchmarks with large working set.
%which utilizes both static and dynamic information provided by compiler and runtime respectively. Compiler collects information such as data access pattern and reuse frequency and passes them to runtime library, and then runtime makes data placement decisions based on both current hardware status and compiler analysis results. Our preliminary evaluation shows that our framework can significantly improve GPU performance and reduce redundant data movement between CPU and GPU for benchmarks with large working set.

\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%


\keywords{GPU, unified virtual memory, compiler optimization}


\maketitle

\input{content/intro}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references} 

\end{document}
